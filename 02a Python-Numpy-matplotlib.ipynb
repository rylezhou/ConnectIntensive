{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 2. Getting to know our tools  \n",
    "\n",
    "## Objectives    \n",
    "\n",
    "- Some Python tips  \n",
    "- Numpy\n",
    "- Pandas \n",
    "- Data visualization with Matplotlib and Seaborn \n",
    "\n",
    " - You should have completed the setup exercises from last week (see _Getting Started_ notebook if you haven't)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 | Python Basics (Review) \n",
    "\n",
    "Some basic topics in Python programming you need to know:\n",
    "\n",
    "* Data types\n",
    "    * Numbers - integer or real. Operators: `+, -, *, /, //, %, **`\n",
    "    * Strings - built-in class, can slice and add like a list. Operators: `+`. `%` is a special format operator\n",
    "    * Lists - arrays, can slice, reverse, sort, pop, append, mutate. Operator: `+`\n",
    "    * Dictionaries - hash table for fast searching\n",
    "    * Booleans - `True` or `False`\n",
    "    * Tuples - immutable arrays, cannot assign a value to a member\n",
    "    * Sets - a collection of unique objects (untyped). This is not indexed, so S[1] is not legal syntax.\n",
    "* Comparison Operators - `==, >, >=, <, <=, !=`\n",
    "* Logic Operators - `and, or, not`\n",
    "* if Statements\n",
    "* for Loops\n",
    "* while Loops\n",
    "* range(start, stop, step) - returns a sequence of numbers from `start`, in increments of `step` less than `stop`.\n",
    "* list comprehension - a convenient construct for manipulating all objects in a list and returning a new list\n",
    "* dict comprehension - similar to list comprehension, but returns a dictionary\n",
    "* functions - like any other modern language \n",
    "* lambda expressions - convenient _anonymous_ single statement functions\n",
    "* zip, map and filter - \n",
    "\n",
    "Here is a link to a pretty [cheat sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PythonForDataScience.pdf) (and the [site](https://www.datacamp.com/community/tutorials/python-data-science-cheat-sheet-basics) that created it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprehensions** \n",
    "\n",
    "Python supports a very convenient syntax for manipulating a collection of objects. Consider this example:\n",
    "1. Create a dictionary `my_dict` where each (English) uppercase character between A and Z is linked to its ASCII numeric value (the numbers 65 to 90. (_Hint:_ You an convert any 1-byte (0-255) integer to its ASCII character using the function `chr` or convert a single character string to its integer value using the function `ord`). \n",
    "\n",
    "You can create a dictionary by using `dict(A)` where A is a special list structure -- a list of lists of two elements each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [['A', ord('A')], ['B', ord('B')]]\n",
    "dict(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Another way is to start with an empty list and then add them one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {} # Create an empty dictionary\n",
    "my_dict['A'] = ord('A')\n",
    "my_dict['B'] = ord('B')\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of 26 such elements using these two methods is clearly possible, but very tedious. Let's not do that!\n",
    "How about a quick loop over 26 numbers? I'll do it for the first 4 - easy enough to change a 4 to a 26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {} # Start fresh\n",
    "for i in range(4):  # You need to know about the range function\n",
    "    my_dict[chr(65 + i)] = 65 + i\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Exercise: \n",
    "Your turn to write the loop using lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO - set up A as a list of 4 elements, each of which is a list like ['A', 65]\n",
    "A = []\n",
    "my_dict = dict(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehension provides a shortened syntax for writing this loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[chr(a), a] for a in range(65, 70)]\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `dictionary comprehension` creates the dictionary we would get after `dict(A)` in one statement. The syntax is similar to a list comprehension with a few differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{chr(a): a for a in range(65, 70)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Tangent_ (or deep dive) to research on your own\n",
    " - you can have nested comprehensions, but they can get a bit hard to read\n",
    " - you can use inline `if .. else` within a list comprehension\n",
    " - you can invoke functions within a list comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions \n",
    "\n",
    "Python uses the reserved word `def` and the syntax below to define a function. It shares the ability to pass in arguments and a get a result back with many other programming languages. Python passes all arguments by reference and therefore the logic inside a function can modify the input. The two functions `square` and `square_` below represent these two options. Run the cell below to confirm your intuition of what values in test and result are after each function call. \n",
    "\n",
    "##### When might it be useful to be able to manipulate the input as in `square_`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x): # Here x is a list of numbers (a vector)\n",
    "    return [k**2 for k in x] # This function returns the element-wise square of the input array (vector)\n",
    "\n",
    "def square_(x): # Here x is a list of numbers (a vector)\n",
    "    for i, k in enumerate(x):\n",
    "        x[i] = k**2\n",
    "    \n",
    "test = range(3)\n",
    "testcopy = test\n",
    "result = square(test)\n",
    "print(test, result)\n",
    "result = square_(test)\n",
    "print(test, result)\n",
    "print(testcopy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notice the value of `testcopy` has also changed even though we didn't explicitly change it! _\n",
    "This is a consequence of how Python manages variable names and something you need to be aware of when you write functions.\n",
    "\n",
    "If you want to preserve the value of an object, to have to copy it using the `copy` module. There are two types of copy called _shallow copy_ and _deep copy_. In the example below we used a shallow copy.  Compare this to the result from the previous cell and notice that testcopy2 retained its value through the same operations that modified testcopy above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "test = range(3)\n",
    "testcopy2 = copy.copy(test)\n",
    "result = square(test)\n",
    "print(test, result)\n",
    "result = square_(test)\n",
    "print(test, result)\n",
    "print(testcopy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Python supports syntax that allows you to name the arguments so you don't have to rely on the order in which they are passed in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract(_from=0, deduct=0): # I used _from as from is a reserved word in python\n",
    "    return _from - deduct\n",
    "\n",
    "print(\"Subtracting 2 from 3 should return {}\".format(subtract(2, 3)))\n",
    "print(\"This subtracts 3 from 2 and returns {}\".format(subtract(3, 2)))\n",
    "print(\"Using names overrides the order - subtracting 2 from 3 returns {}\".format(subtract(_from=3, deduct=2)))\n",
    "print(\"Subtract has defaults so we don't need to pass in arguments each time\".format(subtract()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see the use of named arguments a lot in `sklearn`. Many of the model functions (Regressors or Classifiers) \n",
    "have a large number of arguments or parameters that are conveniently chosen to get started quickly. All the arguments\n",
    "can be \"tweaked\" while refining the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Expressions\n",
    "\n",
    "Sometimes you want to write a line of code that needs to be applied to a list or dictionary but you don't want to have to name it to keep all the code togther (you often see this with a pandas DataFrame's `apply` method). Python provides a convenient way to define these functions using what is known as a `lambda` expression or function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfunction = lambda var: var*2\n",
    "print(lfunction)\n",
    "\n",
    "# Let's use it \n",
    "print(lfunction(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the function doesn't have a name, if we don't assign it to a name, we can't really use it. On the other hand, if we _do_ assign it a name, then we lose one if its key advanages (that it doesn' need a name). As a result, like `anonymous` functions in other languages, you often see `lambda` as arguments to other functions.\n",
    "\n",
    "#### Map and Filter\n",
    "`Map` and `filter` are two such functions that can make effective use of lambda functions. `Shift-enter` through the next four cells and see if you can make sense of these two functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]\n",
    "?map\n",
    "map(lfunction, x) # lfunction (named function) returns the value multiplied by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(lambda var: var**2, x) # An example using a lambda function with no name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?filter\n",
    "filter(lambda var: var%2 == 0, x) # returns all the even elements in the input list x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final caveat for today's lesson -- while `lambda` functions are convenient, they are costly to run as they need to be compiled each time they are encountered during execution. Use them with care, but when you see them in someone else's code, you should know what these expressions mean.\n",
    "\n",
    "\n",
    "## 2 | Data visualization with matplotlib (and seaborn)\n",
    "\n",
    "`matplotlib` is the library of choice for data visualization in python. Other libraries that provide visualization, e.g., `pandas` provide methods using the implementation in `matplotlib`.\n",
    "\n",
    "`matplotlib` is very flexible, but that makes using it for complex plots somewhat challenging. `seaborn` is one of a collection of other libraries that provide wrappers around matplotlib for these more advanced plots.\n",
    "\n",
    "Let's start by importing the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    print(\"Successfully imported numpy! Version {}\".format(np.version.version))\n",
    "except ImportError:\n",
    "    print(\"Could not import numpy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"Successfully imported pandas! Version {}\".format(pd.__version__))\n",
    "except ImportError:\n",
    "    print(\"Could not import pandas!\")\n",
    "    \n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"Successfully imported matplotlib! Version {}\".format(matplotlib.__version__))\n",
    "except ImportError:\n",
    "    print(\"Could not import matplotlib!\")\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    print(\"Successfully imported seaborn! Version {}\".format(sns.__version__))\n",
    "except ImportError:\n",
    "    print(\"Could not import seaborn!\")\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple one-column dataframe of random numbers\n",
    "data = pd.DataFrame(np.random.random(1000)*100)\n",
    "data.columns = ['Numbers']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Titanic disaster practice project, you saw how you could plot histograms for a DataFrame object. Here is another type of plot called a density (for _probability density_) plot. This displays a best guess for the continuous probability distribution that could have led to the data sample. \n",
    "###### From the figure you see after you run the cell, can you tell what distribution we actually used when we used the `np.random.random` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.density()  # can specify number of bins\n",
    "plt.xlabel('Random Number')\n",
    "#plt.ylabel('Frequency')  # We don't need to create the ylabel as the DataFrame.plot already does that for us\n",
    "plt.title('Density of Random Numbers');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many available plot types in pandas visualization, e.g, \n",
    " - data.plot.area     \n",
    " - data.plot.barh     \n",
    " - data.plot.density  \n",
    " - data.plot.hist     \n",
    " - data.plot.line     \n",
    " - data.plot.scatter\n",
    " - data.plot.bar      \n",
    " - data.plot.box      \n",
    "\n",
    "Here `data` is a variable name of class `pandas.DataFrame`.\n",
    "\n",
    "Lets try another visualization mixed in with some pandas manipulation. The `np.random.normal` function provides a random sample of number from the normal distrbution centered on its mean with standard deviation as another parameter. Use ? to figure out what the 50 and 10 correspond to.\n",
    "\n",
    "We create a dataframe with three columns, one of which is a series of random numbers drawn from a normal distribution. The first column is a simple sequence and the third column is a label whose value is either 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.random.normal(50, 10, 200)\n",
    "\n",
    "data_g = pd.DataFrame({\"idx\":np.arange(1,201), \"G\":g, \"label\":np.random.uniform(0,1.0, 200)})\n",
    "data_g[data_g.label > 0.8].label = 2.0\n",
    "data_g[data_g.label < 2.0].label = 1.0\n",
    "\n",
    "data_g.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a couple of plots showing some parameters you can change and see what they do\n",
    " s - size of the symbols that are plotted (notice they are not all the same)\n",
    " c - color of the symbols\n",
    " alpha - transparency (between 0 and 1)\n",
    " \n",
    "The last line uses a `matplotlib` function `scatter` to plot two vectors X and Y (one element each) in a different color size and transparency. There are many other parameters and styles you can use to make pretty plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = np.array(data_g.G) + 2.0\n",
    "data_g.plot.scatter(x=\"idx\", y=\"G\", s=sz, c=\"blue\", alpha=0.2)\n",
    "plt.scatter([100], data_g[['G']].mean(), c='red', alpha=0.4, s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "That's most of the walkthrough. Let's put together a few of the concepts reviewed above toward our in-class topic on metrics and errors.\n",
    "\n",
    "1. Create a numpy array with 100 elements linearly spaced between 0 and 10. Call it `X`.\n",
    "2. A line or a inear function of x would be an array whose elements are $ m \\times x + b $ where $ m $ and $ b $ are parameters. Create a function called f_line which takes $m$, $b$, and `X` as arguments and returns the linear function of `X`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "X = 0\n",
    "def f_line(m, b, X):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've put together a function `quick_plot` that creates a scatter plot of input vectors X and Y and superimposes a line plot of a prediction vector (model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quick_plot(X, Y, model):\n",
    "    plt.figure(2)\n",
    "    plt.scatter(X, Y, c=\"blue\", alpha=0.3, s=50.0 )\n",
    "    plt.plot(X, model, c=\"gray\")\n",
    "    plt.ylim(Y.min(), Y.max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell with different values of m,b and sigma and note the results for large ($ \\approx 5.0 $) and small ($ \\approx 0.1 $) `sigma`. The pre-filled values for the parameters are for you to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Assign values to m and b (keep them between -1.0 and 1.0)\n",
    "Y=f_line(m=0.2, b=-0.3, X=X);\n",
    "#TODO - Assign a value to sigma (between 0.1 and 5.0)\n",
    "sigma = 1.0\n",
    "\n",
    "# r is a vector of random numbers drawn from a normal distribution centered on 0, with a standard deviation of sigma.\n",
    "# quick_plot overlays the \"observed\" noisy data (Y+random values) and the underlying true value (Y).\n",
    "r =  np.random.normal(0, sigma, len(X))\n",
    "quick_plot(X, Y + r, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 | Mean Squared Error\n",
    "\n",
    "Let's look at the previous exercise a little bit more. We know that the true values masked by random noise are given by Y (we will denote it as $\\hat{Y}$. Our _observed_ vector is Y+r; lets call it $O$. Calculate the MSE of Y and Y+r using numpy arrays.\n",
    "$$ MSE = {\\Sigma_{i=0}^N (O_i - \\hat{y_i})^2 \\over N } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate another trial function Z, using f_line with slightly different inputs and calculate the MSE for this model. Do you think its possible to get a _lower_ MSE with the \"wrong\" trial function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "Z = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
